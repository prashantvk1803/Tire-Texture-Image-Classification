{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d149cbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:48:26.125235Z",
     "iopub.status.busy": "2024-03-14T20:48:26.124903Z",
     "iopub.status.idle": "2024-03-14T20:48:32.402611Z",
     "shell.execute_reply": "2024-03-14T20:48:32.401750Z"
    },
    "papermill": {
     "duration": 6.288818,
     "end_time": "2024-03-14T20:48:32.405233",
     "exception": false,
     "start_time": "2024-03-14T20:48:26.116415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Import Library\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as skm\n",
    "import copy\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16f9770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:48:32.422186Z",
     "iopub.status.busy": "2024-03-14T20:48:32.421251Z",
     "iopub.status.idle": "2024-03-14T20:48:32.425668Z",
     "shell.execute_reply": "2024-03-14T20:48:32.424792Z"
    },
    "papermill": {
     "duration": 0.014912,
     "end_time": "2024-03-14T20:48:32.427720",
     "exception": false,
     "start_time": "2024-03-14T20:48:32.412808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaef8221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:48:32.442828Z",
     "iopub.status.busy": "2024-03-14T20:48:32.442561Z",
     "iopub.status.idle": "2024-03-14T20:48:32.449842Z",
     "shell.execute_reply": "2024-03-14T20:48:32.449045Z"
    },
    "papermill": {
     "duration": 0.016957,
     "end_time": "2024-03-14T20:48:32.451764",
     "exception": false,
     "start_time": "2024-03-14T20:48:32.434807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify image size\n",
    "img_size = 512\n",
    "\n",
    "# Making function for create data from path\n",
    "def create_data():\n",
    "\n",
    "    cracked = '/kaggle/input/custom-tire512/custom_tire512/dataset/defective'\n",
    "    normal = '/kaggle/input/custom-tire512/custom_tire512/dataset/normal'\n",
    "\n",
    "\n",
    "\n",
    "    # Labels for train and test\n",
    "    Labels = {cracked:0, normal:1}\n",
    "\n",
    "    # Initializing list for storing train and test data\n",
    "    data = []\n",
    "\n",
    "    # Initializing list for storing train and test label\n",
    "    labels = np.array([])\n",
    "\n",
    "    # Looping through each label\n",
    "    for label in Labels:\n",
    "\n",
    "        # Looping through cracked train data\n",
    "        for ls in os.listdir(label):\n",
    "\n",
    "            # Join each ls element with file path\n",
    "            path = os.path.join(label, ls)\n",
    "\n",
    "            # Read images from path using cv2\n",
    "            img = cv2.imread(path, 0)\n",
    "            img = cv2.resize(img, (img_size, img_size))\n",
    "\n",
    "            # Adding data into data and labels list\n",
    "            data.append(np.array(img))\n",
    "            labels = np.append(labels, Labels[label])\n",
    "\n",
    "    return np.array(data), labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "534b8c3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:48:32.466026Z",
     "iopub.status.busy": "2024-03-14T20:48:32.465759Z",
     "iopub.status.idle": "2024-03-14T20:49:36.984439Z",
     "shell.execute_reply": "2024-03-14T20:49:36.983315Z"
    },
    "papermill": {
     "duration": 64.535083,
     "end_time": "2024-03-14T20:49:36.993454",
     "exception": false,
     "start_time": "2024-03-14T20:48:32.458371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data with shape (5764, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "combined_data, combined_label = create_data()\n",
    "\n",
    "print(f\"Train data with shape {combined_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c73c870c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:49:37.009763Z",
     "iopub.status.busy": "2024-03-14T20:49:37.009421Z",
     "iopub.status.idle": "2024-03-14T20:49:37.016377Z",
     "shell.execute_reply": "2024-03-14T20:49:37.015464Z"
    },
    "papermill": {
     "duration": 0.017204,
     "end_time": "2024-03-14T20:49:37.018353",
     "exception": false,
     "start_time": "2024-03-14T20:49:37.001149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_duplicates(images, labels):\n",
    "    # Convert images to grayscale\n",
    "    grayscale_images = images\n",
    "\n",
    "    # Calculate hash values for each image\n",
    "    hash_values = [np.sum(image.astype(np.float32)) for image in grayscale_images]\n",
    "\n",
    "    # Create a dictionary to store seen hash values\n",
    "    seen_hash_values = {}\n",
    "\n",
    "    # Remove duplicate images and labels based on hash values\n",
    "    filtered_images = []\n",
    "    filtered_labels = []\n",
    "    for hash_value, image, label in zip(hash_values, images, labels):\n",
    "        if hash_value not in seen_hash_values:\n",
    "            seen_hash_values[hash_value] = True\n",
    "            filtered_images.append(image)\n",
    "            filtered_labels.append(label)\n",
    "\n",
    "    return np.array(filtered_images, dtype = np.uint8), np.array(filtered_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c03b24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:49:37.034065Z",
     "iopub.status.busy": "2024-03-14T20:49:37.033737Z",
     "iopub.status.idle": "2024-03-14T20:49:38.204174Z",
     "shell.execute_reply": "2024-03-14T20:49:38.203056Z"
    },
    "papermill": {
     "duration": 1.180888,
     "end_time": "2024-03-14T20:49:38.206564",
     "exception": false,
     "start_time": "2024-03-14T20:49:37.025676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data with shape (3934, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "combined_data, combined_label = drop_duplicates(combined_data, combined_label)\n",
    "print(f\"Train data with shape {combined_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb0c243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:49:38.222978Z",
     "iopub.status.busy": "2024-03-14T20:49:38.222630Z",
     "iopub.status.idle": "2024-03-14T20:49:38.229397Z",
     "shell.execute_reply": "2024-03-14T20:49:38.228337Z"
    },
    "papermill": {
     "duration": 0.017348,
     "end_time": "2024-03-14T20:49:38.231486",
     "exception": false,
     "start_time": "2024-03-14T20:49:38.214138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 0: 2013\n",
      "Count of 1: 1921\n"
     ]
    }
   ],
   "source": [
    "np.unique(combined_label)\n",
    "\n",
    "count_0 = np.count_nonzero(combined_label == 0)\n",
    "count_1 = np.count_nonzero(combined_label == 1)\n",
    "\n",
    "print(\"Count of 0:\", count_0)\n",
    "print(\"Count of 1:\", count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3841e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:49:38.247639Z",
     "iopub.status.busy": "2024-03-14T20:49:38.247362Z",
     "iopub.status.idle": "2024-03-14T20:49:38.251919Z",
     "shell.execute_reply": "2024-03-14T20:49:38.251086Z"
    },
    "papermill": {
     "duration": 0.015005,
     "end_time": "2024-03-14T20:49:38.253934",
     "exception": false,
     "start_time": "2024-03-14T20:49:38.238929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def auto_contrast_brightness(gray):\n",
    "#     # Calculate histogram\n",
    "#     hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "\n",
    "#     # Find minimum and maximum non-zero intensity values\n",
    "#     min_val = np.where(hist > 0)[0][0]\n",
    "#     max_val = np.where(hist > 0)[0][-1]\n",
    "\n",
    "#     # Calculate new contrast factor (alpha)\n",
    "#     alpha = 255.0 / (max_val - min_val) if max_val != min_val else 0  # Avoid division by zero\n",
    "\n",
    "#     # Calculate new brightness factor (beta) to center the histogram\n",
    "#     mid_point = (min_val + max_val) / 2.0\n",
    "#     beta = -min_val * alpha\n",
    "\n",
    "#     # Apply contrast and brightness adjustments\n",
    "#     adjusted = cv2.convertScaleAbs(gray, alpha=alpha, beta=beta)\n",
    "\n",
    "#     return adjusted\n",
    "\n",
    "\n",
    "# auto_contrast_brightness(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6017058e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:49:38.269516Z",
     "iopub.status.busy": "2024-03-14T20:49:38.269242Z",
     "iopub.status.idle": "2024-03-14T20:49:41.190761Z",
     "shell.execute_reply": "2024-03-14T20:49:41.189857Z"
    },
    "papermill": {
     "duration": 2.93205,
     "end_time": "2024-03-14T20:49:41.193256",
     "exception": false,
     "start_time": "2024-03-14T20:49:38.261206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_data = combined_data/np.max(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6efe90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:49:41.210197Z",
     "iopub.status.busy": "2024-03-14T20:49:41.209842Z",
     "iopub.status.idle": "2024-03-14T20:49:43.581227Z",
     "shell.execute_reply": "2024-03-14T20:49:43.580269Z"
    },
    "papermill": {
     "duration": 2.383045,
     "end_time": "2024-03-14T20:49:43.583741",
     "exception": false,
     "start_time": "2024-03-14T20:49:41.200696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_label, test_label = train_test_split(combined_data,combined_label, test_size=.1,\n",
    "                                                                    stratify=combined_label, random_state = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490d5018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:49:43.599597Z",
     "iopub.status.busy": "2024-03-14T20:49:43.599004Z",
     "iopub.status.idle": "2024-03-14T20:49:43.603588Z",
     "shell.execute_reply": "2024-03-14T20:49:43.602754Z"
    },
    "papermill": {
     "duration": 0.014903,
     "end_time": "2024-03-14T20:49:43.605866",
     "exception": false,
     "start_time": "2024-03-14T20:49:43.590963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# noise_traindata = copy.deepcopy(train_data)\n",
    "# noise_traindata = (noise_traindata + 0.25*np.random.rand(*noise_traindata.shape) / 1.1)\n",
    "# noise_traindata = np.clip(noise_traindata, 0, 1) \n",
    "\n",
    "# train_data = np.concatenate((train_data, noise_traindata))\n",
    "# train_label = np.concatenate((train_label, train_label))\n",
    "# print(train_data.shape)\n",
    "# print(train_label.shape)\n",
    "\n",
    "# random_idx = np.random.randint(low=0, high=train_data.shape[0]/2, size=10)\n",
    "\n",
    "# # Initializing fig and ax variables\n",
    "# fig, axs = plt.subplots(2, 5, figsize=(16,8))\n",
    "\n",
    "# # Looping through each axs\n",
    "# for i, ax in enumerate(axs.flatten()):\n",
    "\n",
    "#     # Showing image\n",
    "#     ax.imshow(noise_traindata[random_idx[i],:], cmap='gray')\n",
    "#     ax.axis('off')\n",
    "    \n",
    "#     # Set title for each image\n",
    "#     if train_label[random_idx[i]] ==0:\n",
    "#         ax.set_title(f\"Cracked tire\")\n",
    "#     else:\n",
    "#         ax.set_title(f\"Normal tire\")\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e5213c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:49:43.621862Z",
     "iopub.status.busy": "2024-03-14T20:49:43.621326Z",
     "iopub.status.idle": "2024-03-14T20:49:49.019855Z",
     "shell.execute_reply": "2024-03-14T20:49:49.018831Z"
    },
    "papermill": {
     "duration": 5.409343,
     "end_time": "2024-03-14T20:49:49.022447",
     "exception": false,
     "start_time": "2024-03-14T20:49:43.613104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data with shape torch.Size([3540, 1, 512, 512])\n",
      "Test data with shape torch.Size([394, 1, 512, 512])\n",
      "Train label with shape torch.Size([3540, 1])\n",
      "Test label with shape torch.Size([394, 1])\n"
     ]
    }
   ],
   "source": [
    "train_dataT = torch.tensor(train_data.reshape(train_data.shape[0], channel, img_size, img_size)).float()\n",
    "test_dataT = torch.tensor(test_data.reshape(test_data.shape[0], channel, img_size, img_size)).float()\n",
    "# Label has to be a vector\n",
    "train_labelT = torch.tensor(train_label.reshape(-1, 1)).float()\n",
    "test_labelT = torch.tensor(test_label.reshape(-1, 1)).float()\n",
    "\n",
    "print(f\"Train data with shape {train_dataT.shape}\")\n",
    "print(f\"Test data with shape {test_dataT.shape}\")\n",
    "\n",
    "print(f\"Train label with shape {train_labelT.shape}\")\n",
    "print(f\"Test label with shape {test_labelT.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd0860",
   "metadata": {
    "papermill": {
     "duration": 0.00691,
     "end_time": "2024-03-14T20:49:49.037031",
     "exception": false,
     "start_time": "2024-03-14T20:49:49.030121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "342c623f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:49:49.053738Z",
     "iopub.status.busy": "2024-03-14T20:49:49.052872Z",
     "iopub.status.idle": "2024-03-14T20:49:49.060948Z",
     "shell.execute_reply": "2024-03-14T20:49:49.059830Z"
    },
    "papermill": {
     "duration": 0.019104,
     "end_time": "2024-03-14T20:49:49.063365",
     "exception": false,
     "start_time": "2024-03-14T20:49:49.044261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split 50% to test and another to validation\n",
    "# test_data_split, val_data_split, test_label_split, val_label_split = train_test_split(\n",
    "#                                                                     test_dataT, test_labelT, test_size=.5,\n",
    "#                                                                     stratify=test_labelT, random_state=42)\n",
    "\n",
    "# Create TensorDataset Object\n",
    "train_tensor = torch.utils.data.TensorDataset(train_dataT, train_labelT)\n",
    "test_tensor = torch.utils.data.TensorDataset(test_dataT, test_labelT)\n",
    "\n",
    "\n",
    "# Create DataLoader Object\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_tensor, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_tensor, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c92deb4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:49:49.085590Z",
     "iopub.status.busy": "2024-03-14T20:49:49.085292Z",
     "iopub.status.idle": "2024-03-14T20:49:49.224495Z",
     "shell.execute_reply": "2024-03-14T20:49:49.223572Z"
    },
    "papermill": {
     "duration": 0.152868,
     "end_time": "2024-03-14T20:49:49.226766",
     "exception": false,
     "start_time": "2024-03-14T20:49:49.073898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(printsize=False):\n",
    "\n",
    "    # CNN model class\n",
    "\n",
    "    class TireNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(TireNet, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(channel, 32, kernel_size=2, stride=1, padding=1)  # Increased filter size to 3\n",
    "            self.bn1 = nn.BatchNorm2d(32)\n",
    "            self.conv12 = nn.Conv2d(32, 64, kernel_size=2, stride=1, padding=1)  # Increased filter size to 3\n",
    "            self.bn12 = nn.BatchNorm2d(64)\n",
    "            self.conv2 = nn.Conv2d(64, 128, kernel_size=2, stride=1, padding=1)\n",
    "            self.bn2 = nn.BatchNorm2d(128)\n",
    "            self.conv3 = nn.Conv2d(128, 256, kernel_size=2, stride=1, padding=1)\n",
    "            self.bn3 = nn.BatchNorm2d(256)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.dp1 = nn.Dropout2d(p=0.0325)\n",
    "            \n",
    "#             self.fc1 = nn.Linear(256 * 28 * 28, 1)  # Adjusted for 32x32 input and 3x3 filters\n",
    "            self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "    \n",
    "            self.gapS = nn.AdaptiveAvgPool2d((1, 1))\n",
    "    \n",
    "            self.conv5 = nn.Conv2d(256,128, kernel_size=2, stride=1, padding=1)\n",
    "            self.bn5 = nn.BatchNorm2d(128)\n",
    "            self.conv56 = nn.Conv2d(128,64, kernel_size=2, stride=1, padding=1)\n",
    "            self.bn56 = nn.BatchNorm2d(64)\n",
    "            self.conv6 = nn.Conv2d(64,32, kernel_size=2, stride=1, padding=1)\n",
    "            self.bn6 = nn.BatchNorm2d(32)\n",
    "            self.conv7 = nn.Conv2d(32,1, kernel_size=2, stride=1, padding=1)\n",
    "            \n",
    "            \n",
    "            self.convS = nn.Conv2d(128,1, kernel_size=2, stride=1, padding=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.leaky_relu(self.bn1(self.conv1(x)), 0.01) \n",
    "            x = self.dp1(x)\n",
    "            x = self.pool(x)\n",
    "            x = F.leaky_relu(self.bn12(self.conv12(x)), 0.01) \n",
    "            x = self.dp1(x)\n",
    "            x = self.pool(x)\n",
    "            x = F.leaky_relu(self.bn2(self.conv2(x)), 0.01) \n",
    "            x = self.dp1(x)\n",
    "            x = self.pool(x)\n",
    "            x2=x\n",
    "            x = F.leaky_relu(self.bn3(self.conv3(x)), 0.01) \n",
    "            x = self.dp1(x)\n",
    "            x = self.pool(x)\n",
    "            \n",
    "            \n",
    "#             x = x.view(-1, 256 * 28* 28)\n",
    "#             x = (self.fc1(x))\n",
    "            x = F.leaky_relu(self.bn5(self.conv5(x)), 0.01)\n",
    "            x = self.dp1(x)\n",
    "            x = self.pool(x)\n",
    "            x = F.leaky_relu(self.bn56(self.conv56(x)), 0.01)\n",
    "            x = self.dp1(x)\n",
    "            x = self.pool(x)\n",
    "            x = F.leaky_relu(self.bn6(self.conv6(x)), 0.01)\n",
    "            x = self.dp1(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.conv7(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.gap(x)\n",
    "            \n",
    "            \n",
    "            x2 = self.convS(x2)\n",
    "            x2 = self.pool(x2)\n",
    "            x2 = self.gapS(x2)\n",
    "            x2 = x2.squeeze(-1).squeeze(-1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            x = x.squeeze(-1).squeeze(-1)\n",
    "            \n",
    "            x += x2\n",
    "            return x\n",
    "\n",
    "    # Create variables for model, loss function, optimizer\n",
    "    model = TireNet()\n",
    "    lossfunc = nn.BCEWithLogitsLoss()\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.005, weight_decay = 0.005, momentum = 0.9)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "\n",
    "    return model, lossfunc, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d3e6e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:49:49.243230Z",
     "iopub.status.busy": "2024-03-14T20:49:49.242362Z",
     "iopub.status.idle": "2024-03-14T20:49:49.340062Z",
     "shell.execute_reply": "2024-03-14T20:49:49.339034Z"
    },
    "papermill": {
     "duration": 0.108054,
     "end_time": "2024-03-14T20:49:49.342149",
     "exception": false,
     "start_time": "2024-03-14T20:49:49.234095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for GPU\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faab0656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:49:49.358538Z",
     "iopub.status.busy": "2024-03-14T20:49:49.358160Z",
     "iopub.status.idle": "2024-03-14T20:49:49.375785Z",
     "shell.execute_reply": "2024-03-14T20:49:49.375028Z"
    },
    "papermill": {
     "duration": 0.02823,
     "end_time": "2024-03-14T20:49:49.377779",
     "exception": false,
     "start_time": "2024-03-14T20:49:49.349549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create train_model function\n",
    "def train_model(model, lossfunc, optimizer, n_epochs, train_data, val_data):\n",
    "\n",
    "    # For storing best perfrom model!\n",
    "    bestmodel = {'acc': 0, 'net': None}\n",
    "\n",
    "    # Initializing variables for storing result\n",
    "\n",
    "    # Use GPU for our model\n",
    "    model = model.to(device)\n",
    "    val_losses=0;\n",
    "    count=0;\n",
    "\n",
    "    # Training loop\n",
    "    for epochi in range(n_epochs):\n",
    "\n",
    "        # Training mode\n",
    "        model.train()\n",
    "\n",
    "        # Variable for storing result each batch\n",
    "        batch_train = []\n",
    "        batch_loss = []\n",
    "\n",
    "        # Training in train_data\n",
    "        for X, y in train_data:\n",
    "\n",
    "            # Push data into GPU\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Predict model\n",
    "            pred = model(X)\n",
    "            # How many error in this prediction ? (compute for error)\n",
    "            loss = lossfunc(pred, y)\n",
    "\n",
    "            # Set gradient to zero\n",
    "            optimizer.zero_grad()\n",
    "            # Compute Loss\n",
    "            loss.backward()\n",
    "            # Do back prop\n",
    "            optimizer.step()\n",
    "\n",
    "            # Storing loss this batch into batch_loss\n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "            # move pred, y to CPU\n",
    "            pred = pred.cpu()\n",
    "            y = y.cpu()\n",
    "\n",
    "            # Computing accuracy and storing result\n",
    "            matches = ((pred>0)==y).float()\n",
    "            batch_train.append(100*torch.mean(matches).item())\n",
    "\n",
    "        # Compute average of batch_train and batch_loss\n",
    "        train_acc = (np.mean(batch_train))\n",
    "        train_losses = (np.mean(batch_loss))\n",
    "\n",
    "        # Using eval mode\n",
    "        model.eval()\n",
    "\n",
    "        batch_val = []\n",
    "        batch_val_loss = []\n",
    "        \n",
    "        # Testing in validation_data to avoid overfitting\n",
    "        for X, y in val_data:\n",
    "\n",
    "            # Push data into GPU\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Using torch.no_grad() to switch off gradient computation\n",
    "            with torch.no_grad():\n",
    "                # Predict model\n",
    "                pred = model(X)\n",
    "\n",
    "            loss = lossfunc(pred, y)\n",
    "            # Store test loss\n",
    "            batch_val_loss.append(loss.item())\n",
    "\n",
    "            # move pred to CPU\n",
    "            pred = pred.cpu()\n",
    "            y = y.cpu()\n",
    "\n",
    "            matches = ((pred>0)==y).float()\n",
    "            batch_val.append(100*torch.mean(matches).item())\n",
    "\n",
    "        val_acc = (np.mean(batch_val))\n",
    "        \n",
    "        if(val_losses<(np.mean(batch_val_loss))):\n",
    "            count =count+1;\n",
    "#         if(count>10):\n",
    "#             break;\n",
    "        val_losses = (np.mean(batch_val_loss))\n",
    "        \n",
    "        \n",
    "        # Craete msg for printing result\n",
    "        msg = f\"Epoch {epochi+1} out of {n_epochs} with Train acc {train_acc:.2f}% Val acc {val_acc:.2f}% and Val Loss {val_losses:.8f}\"\n",
    "        sys.stdout.write('\\r'+msg)\n",
    "\n",
    "        # Storing bestmodel\n",
    "        if val_acc > bestmodel['acc']:\n",
    "\n",
    "            bestmodel['acc'] = val_acc.item()\n",
    "            bestmodel['net'] = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    return train_acc, val_acc, train_losses, val_losses, model , bestmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "515a7c52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:49:49.393735Z",
     "iopub.status.busy": "2024-03-14T20:49:49.393085Z",
     "iopub.status.idle": "2024-03-15T01:30:11.354825Z",
     "shell.execute_reply": "2024-03-15T01:30:11.353791Z"
    },
    "papermill": {
     "duration": 16822.005987,
     "end_time": "2024-03-15T01:30:11.390904",
     "exception": false,
     "start_time": "2024-03-14T20:49:49.384917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300 out of 300 with Train acc 99.29% Val acc 97.84% and Val Loss 0.09092644"
     ]
    }
   ],
   "source": [
    "# Create model instance\n",
    "model, lossfunc, optimizer = create_model()\n",
    "# Train with 150 epochs\n",
    "numepochs = 300\n",
    "train_acc, val_acc, train_losses, val_losses, model, bestmodel = train_model(model, lossfunc, optimizer, numepochs, train_loader, test_loader)\n",
    "\n",
    "#train_acc, val_acc, train_losses, val_losses, model = train_model(model, lossfunc, optimizer, numepochs, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20fa41e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T01:30:11.460072Z",
     "iopub.status.busy": "2024-03-15T01:30:11.459667Z",
     "iopub.status.idle": "2024-03-15T01:30:11.485001Z",
     "shell.execute_reply": "2024-03-15T01:30:11.484111Z"
    },
    "papermill": {
     "duration": 0.062734,
     "end_time": "2024-03-15T01:30:11.487283",
     "exception": false,
     "start_time": "2024-03-15T01:30:11.424549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recreate new model\n",
    "torch.save(model.state_dict(), 'model.pth') \n",
    "\n",
    "    \n",
    "# Load best model\n",
    "torch.save(bestmodel['net'], 'bestmodel1.pth') \n",
    "bestmodel = {'acc': 0, 'net': None}\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bbeea52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T01:30:11.554011Z",
     "iopub.status.busy": "2024-03-15T01:30:11.553668Z",
     "iopub.status.idle": "2024-03-15T01:30:13.507905Z",
     "shell.execute_reply": "2024-03-15T01:30:13.506925Z"
    },
    "papermill": {
     "duration": 1.988737,
     "end_time": "2024-03-15T01:30:13.509877",
     "exception": false,
     "start_time": "2024-03-15T01:30:11.521140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 97.72%\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = create_model()[0].to(device)  # Move model to GPU\n",
    "model.load_state_dict(torch.load('bestmodel1.pth'))\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Iterate over all batches in the test loader\n",
    "for test_set, test_set_label in test_loader:\n",
    "    test_set, test_set_label = test_set.to(device), test_set_label.to(device)  # Move data to GPU\n",
    "\n",
    "    # Forward pass through model\n",
    "    test_result = model(test_set)  # No need for .cpu() as results are already on GPU\n",
    "\n",
    "    # Calculate accuracy for each batch\n",
    "    correct_batch = (test_result > 0) == test_set_label\n",
    "    correct += torch.sum(correct_batch).item()  # Move correct_batch back to CPU for accumulation\n",
    "    total += correct_batch.size(0)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(\"Test accuracy is {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa314dc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T01:30:13.572178Z",
     "iopub.status.busy": "2024-03-15T01:30:13.571593Z",
     "iopub.status.idle": "2024-03-15T01:30:15.163636Z",
     "shell.execute_reply": "2024-03-15T01:30:15.162237Z"
    },
    "papermill": {
     "duration": 1.625033,
     "end_time": "2024-03-15T01:30:15.165583",
     "exception": true,
     "start_time": "2024-03-15T01:30:13.540550",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 14.75 GiB total capacity; 14.08 GiB already allocated; 39.06 MiB free; 14.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m test_set, test_set_label \u001b[38;5;241m=\u001b[39m test_set\u001b[38;5;241m.\u001b[39mto(device), test_set_label\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move data to GPU\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Forward pass through model\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m test_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# No need for .cpu() as results are already on GPU\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Calculate accuracy for each batch\u001b[39;00m\n\u001b[1;32m     18\u001b[0m correct_batch \u001b[38;5;241m=\u001b[39m (test_result \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m test_set_label\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[14], line 46\u001b[0m, in \u001b[0;36mcreate_model.<locals>.TireNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n\u001b[1;32m     45\u001b[0m x2\u001b[38;5;241m=\u001b[39mx\n\u001b[0;32m---> 46\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn3\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     47\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdp1(x)\n\u001b[1;32m     48\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:1632\u001b[0m, in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1630\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mleaky_relu_(\u001b[38;5;28minput\u001b[39m, negative_slope)\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1632\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_slope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 14.75 GiB total capacity; 14.08 GiB already allocated; 39.06 MiB free; 14.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = create_model()[0].to(device)  # Move model to GPU\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "# Iterate over all batches in the test loader\n",
    "for test_set, test_set_label in test_loader:\n",
    "    test_set, test_set_label = test_set.to(device), test_set_label.to(device)  # Move data to GPU\n",
    "\n",
    "    # Forward pass through model\n",
    "    test_result = model(test_set)  # No need for .cpu() as results are already on GPU\n",
    "\n",
    "    # Calculate accuracy for each batch\n",
    "    correct_batch = (test_result > 0) == test_set_label\n",
    "    correct += torch.sum(correct_batch).item()  # Move correct_batch back to CPU for accumulation\n",
    "    total += correct_batch.size(0)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(\"Test accuracy is {:.2f}%\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4260237,
     "sourceId": 7338041,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4398991,
     "sourceId": 7552822,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4399018,
     "sourceId": 7552861,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4442221,
     "sourceId": 7625309,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16915.894676,
   "end_time": "2024-03-15T01:30:18.237197",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-14T20:48:22.342521",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
